"""
å…­å¤§å› å­é€‰è‚¡ç­–ç•¥
ç‰ˆæœ¬: v1.0
æ›´æ–°æ—¥æœŸ: 2025-12-30

åŸºäºå…­å¤§å› å­çš„ç»¼åˆé€‰è‚¡ç­–ç•¥:
- alpha_pluse: é‡èƒ½å› å­
- alpha_peg: ä¼°å€¼å› å­ï¼ˆè¡Œä¸šæ ‡å‡†åŒ–ï¼‰
- alpha_010: çŸ­å‘¨æœŸä»·æ ¼è¶‹åŠ¿
- alpha_038: ä»·æ ¼å¼ºåº¦
- alpha_120cq: ä»·æ ¼ä½ç½®
- cr_qfq: åŠ¨é‡å› å­
"""

import pandas as pd
import numpy as np
import sys
import os
import argparse
from datetime import datetime
from typing import Dict, List, Tuple, Optional

sys.path.insert(0, '/home/zcy/alpha006_20251223')

import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from core.utils.data_loader import data_loader
from core.utils.db_connection import db
from core.config.params import get_strategy_param, get_factor_param
from factors.price.PRI_TREND_4D_V2 import create_factor as create_alpha_010
from factors.price.PRI_STR_10D_V2 import create_factor as create_alpha_038
from factors.price.PRI_POS_120D_V2 import create_factor as create_alpha_120cq
from factors.momentum.VOL_EXP_20D_V2 import create_factor as create_alpha_pluse
from factors.valuation.alpha_peg import ValGrowQFactor
from factors.volume.MOM_CR_20D_V2 import create_factor as create_cr_qfq

from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')


class SixFactorStrategy:
    """å…­å¤§å› å­é€‰è‚¡ç­–ç•¥ç±»"""

    def __init__(self, target_date: str, version: str = 'standard'):
        """
        åˆå§‹åŒ–ç­–ç•¥

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ (YYYYMMDD)
            version: ç­–ç•¥ç‰ˆæœ¬ (standard/conservative/aggressive)
        """
        self.target_date = target_date
        self.version = version
        self.params = get_strategy_param('six_factor', version)
        self.filter_stats = {}
        self.factor_data = {}

        logger.info(f"åˆå§‹åŒ–ç­–ç•¥: {self.params['name']}")
        logger.info(f"ç›®æ ‡æ—¥æœŸ: {target_date}, ç‰ˆæœ¬: {version}")

    def get_market_data(self) -> pd.DataFrame:
        """è·å–æµé€šå¸‚å€¼å’Œæˆäº¤é¢æ•°æ®"""
        logger.info("æ­¥éª¤1: è·å–æµé€šå¸‚å€¼å’Œæˆäº¤é¢æ•°æ®...")

        df = data_loader.get_market_cap_and_amount(self.target_date)

        if len(df) == 0:
            raise ValueError(f"æœªè·å–åˆ°æµé€šå¸‚å€¼/æˆäº¤é¢æ•°æ®: {self.target_date}")

        # å•ä½è½¬æ¢
        # circ_mvå•ä½æ˜¯ä¸‡å…ƒï¼Œè½¬æ¢ä¸ºäº¿: ä¸‡å…ƒ / 10000 = äº¿
        df['æµé€šå¸‚å€¼(äº¿)'] = df['circ_mv'] / 10_000
        # amountå•ä½æ˜¯å…ƒï¼Œè½¬æ¢ä¸ºä¸‡: å…ƒ / 10000 = ä¸‡
        df['æˆäº¤é¢(ä¸‡)'] = df['amount'] / 10_000

        logger.info(f"è·å–æµé€šå¸‚å€¼/æˆäº¤é¢æ•°æ®: {len(df)} åªè‚¡ç¥¨")
        self.filter_stats['åˆå§‹è‚¡ç¥¨æ•°'] = len(df)

        return df

    def get_st_stock_list(self) -> List[str]:
        """è·å–STè‚¡ç¥¨åˆ—è¡¨"""
        sql = f"SELECT ts_code FROM stock_st WHERE type = 'ST'"
        data = db.execute_query(sql, ())
        return [row['ts_code'] for row in data]

    def apply_base_filters(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """åº”ç”¨åŸºç¡€è¿‡æ»¤"""
        logger.info("æ­¥éª¤2: åº”ç”¨åŸºç¡€è¿‡æ»¤...")

        initial_count = len(df)
        filter_log = {}

        # 1. å‰”é™¤STè‚¡ç¥¨
        if self.params['filters']['exclude_st']:
            st_stocks = self.get_st_stock_list()
            df = df[~df['ts_code'].isin(st_stocks)]
            filter_log['å‰”é™¤ST'] = initial_count - len(df)
            initial_count = len(df)

        # 2. å‰”é™¤åœç‰Œï¼ˆæˆäº¤é¢ä¸º0æˆ–NaNï¼‰
        if self.params['filters']['exclude_suspension']:
            df = df[df['æˆäº¤é¢(ä¸‡)'] > 0]
            filter_log['å‰”é™¤åœç‰Œ'] = initial_count - len(df)
            initial_count = len(df)

        # 3. å‰”é™¤ä½æµåŠ¨æ€§
        min_amount = self.params['filters']['min_amount'] / 10_000  # è½¬æ¢ä¸ºä¸‡
        df = df[df['æˆäº¤é¢(ä¸‡)'] >= min_amount]
        filter_log['å‰”é™¤ä½æµåŠ¨æ€§'] = initial_count - len(df)
        initial_count = len(df)

        # 4. å‰”é™¤å°å¸‚å€¼ï¼ˆä½¿ç”¨æµé€šå¸‚å€¼ï¼‰
        min_market_cap = self.params['filters']['min_market_cap'] / 100_000_000  # è½¬æ¢ä¸ºäº¿
        df = df[df['æµé€šå¸‚å€¼(äº¿)'] >= min_market_cap]
        filter_log['å‰”é™¤å°å¸‚å€¼'] = initial_count - len(df)
        initial_count = len(df)

        # 5. alpha_pluse = 1 (åªå¯¹è¿‡æ»¤åçš„è‚¡ç¥¨è®¡ç®—)
        if len(df) > 0:
            alpha_pluse_factor = create_alpha_pluse('standard')
            # è·å–è¿‡æ»¤åè‚¡ç¥¨çš„ä»·æ ¼æ•°æ®ï¼ˆéœ€è¦34å¤©æ•°æ®ï¼‰
            stocks = df['ts_code'].tolist()
            price_data = data_loader.get_price_data_for_period(stocks, self.target_date, 34)

            if len(price_data) > 0:
                alpha_pluse_result = alpha_pluse_factor.calculate(price_data)

                if len(alpha_pluse_result) > 0:
                    valid_stocks = alpha_pluse_result[alpha_pluse_result['alpha_pluse'] == 1]['ts_code'].tolist()
                    df = df[df['ts_code'].isin(valid_stocks)]
                    filter_log['alpha_pluse=1'] = initial_count - len(df)
                    initial_count = len(df)
                else:
                    filter_log['alpha_pluse=1'] = initial_count
                    df = df.iloc[0:0]  # Empty dataframe
            else:
                filter_log['alpha_pluse=1'] = initial_count
                df = df.iloc[0:0]  # Empty dataframe
        else:
            filter_log['alpha_pluse=1'] = 0

        self.filter_stats.update(filter_log)
        self.filter_stats['åŸºç¡€è¿‡æ»¤å'] = len(df)

        logger.info(f"åŸºç¡€è¿‡æ»¤åå‰©ä½™: {len(df)} åªè‚¡ç¥¨")
        for key, value in filter_log.items():
            if value > 0:
                logger.info(f"  - {key}: {value}åª")

        return df, filter_log

    def calculate_all_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æ‰€æœ‰å› å­"""
        logger.info("æ­¥éª¤3: è®¡ç®—å„å› å­...")

        stocks = df['ts_code'].tolist()

        # æ·»åŠ è¡Œä¸šæ•°æ®
        logger.info("  è·å–è¡Œä¸šæ•°æ®...")
        industry_data = data_loader.get_industry_data_from_csv(stocks)
        if len(industry_data) > 0:
            df = df.merge(industry_data[['ts_code', 'l1_name']], on='ts_code', how='left')
            df.rename(columns={'l1_name': 'ç”³ä¸‡ä¸€çº§è¡Œä¸š'}, inplace=True)
            logger.info(f"  è¡Œä¸šæ•°æ®å·²æ·»åŠ : {len(industry_data)}æ¡")
        else:
            logger.warning("  æ— æ³•è·å–è¡Œä¸šæ•°æ®")

        # 1. alpha_peg (ä¼°å€¼å› å­ = PE_TTMï¼Œè¿›è¡Œè¡Œä¸šæ ‡å‡†åŒ–)
        logger.info("  è®¡ç®—alpha_peg...")
        try:
            # è·å–PEæ•°æ®
            df_pe, _ = data_loader.get_fina_data(stocks, self.target_date)

            if len(df_pe) > 0:
                # è·å–è¡Œä¸šæ•°æ®
                industry_data = data_loader.get_industry_data_from_csv(stocks)

                if len(industry_data) > 0:
                    # åˆå¹¶è¡Œä¸š
                    df_pe_industry = df_pe.merge(industry_data, on='ts_code', how='left')
                    df_pe_industry['l1_name'] = df_pe_industry['l1_name'].fillna('å…¶ä»–')

                    # è®¡ç®—è¡Œä¸šZ-Score
                    def zscore(group):
                        values = group['pe_ttm'].astype(float)
                        mean = values.mean()
                        std = values.std()
                        if std == 0 or pd.isna(std) or len(values) < 2:
                            return pd.Series([0.0] * len(group), index=group.index)
                        return (values - mean) / std

                    df_pe_industry['alpha_peg_zscore'] = df_pe_industry.groupby('l1_name').apply(zscore).reset_index(level=0, drop=True)

                    # è¿‡æ»¤æ ·æœ¬ä¸è¶³çš„è¡Œä¸š
                    min_samples = 5
                    industry_counts = df_pe_industry.groupby('l1_name').size()
                    valid_industries = industry_counts[industry_counts >= min_samples].index
                    df_pe_industry = df_pe_industry[df_pe_industry['l1_name'].isin(valid_industries)]

                    # åˆå¹¶åˆ°ä¸»æ•°æ®
                    df = df.merge(df_pe_industry[['ts_code', 'alpha_peg_zscore']], on='ts_code', how='left')
                    self.factor_data['alpha_peg'] = df_pe_industry

                    logger.info(f"  alpha_pegè®¡ç®—å®Œæˆ: {len(df_pe_industry)}æ¡è®°å½•")
                else:
                    logger.warning("æ— æ³•è·å–è¡Œä¸šæ•°æ®ï¼Œè·³è¿‡alpha_peg")
            else:
                logger.warning("æ— PEæ•°æ®ï¼Œè·³è¿‡alpha_peg")
        except Exception as e:
            logger.warning(f"alpha_pegè®¡ç®—å¤±è´¥: {e}ï¼Œè·³è¿‡è¯¥å› å­")

        # 2. alpha_010 (çŸ­å‘¨æœŸè¶‹åŠ¿)
        logger.info("  è®¡ç®—alpha_010...")
        alpha_010_factor = create_alpha_010(self.version)
        price_data = data_loader.get_price_data_for_period(stocks, self.target_date, 10)
        alpha_010_result = alpha_010_factor.calculate(price_data)

        if len(alpha_010_result) > 0:
            df = df.merge(alpha_010_result[['ts_code', 'alpha_010']], on='ts_code', how='left')
            self.factor_data['alpha_010'] = alpha_010_result

        # 3. alpha_038 (ä»·æ ¼å¼ºåº¦)
        logger.info("  è®¡ç®—alpha_038...")
        alpha_038_factor = create_alpha_038(self.version)
        # éœ€è¦è‡³å°‘10å¤©æ•°æ®ï¼Œæ‰€ä»¥ä»target_dateå¾€å‰æ¨10å¤©
        price_data_038 = data_loader.get_price_data_for_period(stocks, self.target_date, 10)
        alpha_038_result = alpha_038_factor.calculate(price_data_038)

        if len(alpha_038_result) > 0:
            df = df.merge(alpha_038_result[['ts_code', 'alpha_038']], on='ts_code', how='left')
            self.factor_data['alpha_038'] = alpha_038_result

        # 4. alpha_120cq (ä»·æ ¼ä½ç½®)
        logger.info("  è®¡ç®—alpha_120cq...")
        alpha_120cq_factor = create_alpha_120cq(self.version)
        price_data_120 = data_loader.get_price_data_for_period(stocks, self.target_date, 180)
        alpha_120cq_result = alpha_120cq_factor.calculate(price_data_120, self.target_date)

        if len(alpha_120cq_result) > 0:
            df = df.merge(alpha_120cq_result[['ts_code', 'alpha_120cq']], on='ts_code', how='left')
            self.factor_data['alpha_120cq'] = alpha_120cq_result

        # 5. cr_qfq (åŠ¨é‡å› å­)
        logger.info("  è·å–cr_qfq...")
        cr_qfq_factor = create_cr_qfq(self.version)
        cr_qfq_result = cr_qfq_factor.calculate_by_period(
            self.target_date, stocks
        )

        if len(cr_qfq_result) > 0:
            df = df.merge(cr_qfq_result[['ts_code', 'cr_qfq']], on='ts_code', how='left')
            self.factor_data['cr_qfq'] = cr_qfq_result

        # 6. alpha_pluse (é‡èƒ½å› å­) - ä½œä¸ºç‹¬ç«‹å› å­å‚ä¸æ‰“åˆ†
        logger.info("  è®¡ç®—alpha_pluse...")
        alpha_pluse_factor = create_alpha_pluse('standard')
        # è·å–ä»·æ ¼æ•°æ®ï¼ˆéœ€è¦34å¤©æ•°æ®ï¼‰
        price_data_pluse = data_loader.get_price_data_for_period(stocks, self.target_date, 34)

        if len(price_data_pluse) > 0:
            alpha_pluse_result = alpha_pluse_factor.calculate(price_data_pluse)

            if len(alpha_pluse_result) > 0:
                # alpha_pluseæ˜¯0/1äºŒå…ƒå˜é‡ï¼Œè½¬æ¢ä¸ºæ•°å€¼å‚ä¸è®¡ç®—
                df = df.merge(alpha_pluse_result[['ts_code', 'alpha_pluse']], on='ts_code', how='left')
                self.factor_data['alpha_pluse'] = alpha_pluse_result

                # å°†alpha_pluseè½¬æ¢ä¸ºæ•°å€¼ï¼ˆ0æˆ–1ï¼‰
                df['alpha_pluse'] = pd.to_numeric(df['alpha_pluse'], errors='coerce').fillna(0)

        # è®°å½•å› å­æ•°æ®ç»Ÿè®¡
        logger.info("å› å­æ•°æ®ç»Ÿè®¡:")
        for factor in ['alpha_peg_zscore', 'alpha_010', 'alpha_038', 'alpha_120cq', 'cr_qfq', 'alpha_pluse']:
            if factor in df.columns:
                valid = df[factor].dropna()
                if len(valid) > 0:
                    logger.info(f"  {factor}: {len(valid)}/{len(df)} æœ‰æ•ˆ, å‡å€¼={valid.mean():.2f}")

        return df

    def apply_factor_filters(self, df: pd.DataFrame) -> pd.DataFrame:
        """åº”ç”¨å› å­ç­›é€‰"""
        logger.info("æ­¥éª¤4: åº”ç”¨å› å­ç­›é€‰...")

        initial_count = len(df)
        filter_log = {}

        # å¦‚æœè‚¡ç¥¨æ•°é‡å¤ªå°‘ï¼Œä½¿ç”¨æ›´å®½æ¾çš„ç­›é€‰
        min_threshold = 5 if initial_count >= 20 else 2  # åŠ¨æ€è°ƒæ•´æœ€å°ä¿ç•™æ•°

        # 1. alpha_peg å‰30%ï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼‰
        if 'alpha_peg_zscore' in df.columns and len(df) > min_threshold:
            threshold = self.params['factor_thresholds']['alpha_peg']
            valid_stocks = df.dropna(subset=['alpha_peg_zscore'])
            if len(valid_stocks) > min_threshold:
                cutoff = valid_stocks['alpha_peg_zscore'].quantile(threshold)
                df = df[df['alpha_peg_zscore'] <= cutoff]
                filter_log['alpha_pegå‰30%'] = initial_count - len(df)
                initial_count = len(df)

        # 2. alpha_010 å‰30%ï¼ˆå€¼è¶Šå¤§è¶Šå¥½ï¼‰
        if 'alpha_010' in df.columns and len(df) > min_threshold:
            threshold = self.params['factor_thresholds']['alpha_010']
            valid_stocks = df.dropna(subset=['alpha_010'])
            if len(valid_stocks) > min_threshold:
                cutoff = valid_stocks['alpha_010'].quantile(1 - threshold)
                df = df[df['alpha_010'] >= cutoff]
                filter_log['alpha_010å‰30%'] = initial_count - len(df)
                initial_count = len(df)

        # 3. alpha_038 å‰30%ï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼Œè´Ÿå€¼ï¼‰
        if 'alpha_038' in df.columns and len(df) > min_threshold:
            threshold = self.params['factor_thresholds']['alpha_038']
            valid_stocks = df.dropna(subset=['alpha_038'])
            if len(valid_stocks) > min_threshold:
                cutoff = valid_stocks['alpha_038'].quantile(threshold)
                df = df[df['alpha_038'] <= cutoff]
                filter_log['alpha_038å‰30%'] = initial_count - len(df)
                initial_count = len(df)

        # 4. alpha_120cq åœ¨ [0.2, 0.8] åŒºé—´
        if 'alpha_120cq' in df.columns and len(df) > min_threshold:
            low = self.params['factor_thresholds']['alpha_120cq_low']
            high = self.params['factor_thresholds']['alpha_120cq_high']
            filtered = df[(df['alpha_120cq'] >= low) & (df['alpha_120cq'] <= high)]
            if len(filtered) >= min_threshold:
                df = filtered
                filter_log['alpha_120cq[0.2,0.8]'] = initial_count - len(df)
                initial_count = len(df)

        # 5. cr_qfq å‰40%ï¼ˆå€¼è¶Šå¤§è¶Šå¥½ï¼‰
        if 'cr_qfq' in df.columns and len(df) > min_threshold:
            threshold = self.params['factor_thresholds']['cr_qfq']
            valid_stocks = df.dropna(subset=['cr_qfq'])
            if len(valid_stocks) > min_threshold:
                cutoff = valid_stocks['cr_qfq'].quantile(1 - threshold)
                df = df[df['cr_qfq'] >= cutoff]
                filter_log['cr_qfqå‰40%'] = initial_count - len(df)
                initial_count = len(df)

        # 6. alpha_pluse = 1ï¼ˆé‡èƒ½å› å­ï¼Œå·²åœ¨åŸºç¡€è¿‡æ»¤ä¸­ç­›é€‰ï¼Œè¿™é‡Œä½œä¸ºéªŒè¯ï¼‰
        if 'alpha_pluse' in df.columns and len(df) > min_threshold:
            valid_stocks = df.dropna(subset=['alpha_pluse'])
            before_filter = len(df)
            df = df[valid_stocks['alpha_pluse'] == 1]
            filter_log['alpha_pluse=1'] = before_filter - len(df)
            initial_count = len(df)

        self.filter_stats.update(filter_log)
        self.filter_stats['å› å­ç­›é€‰å'] = len(df)

        logger.info(f"å› å­ç­›é€‰åå‰©ä½™: {len(df)} åªè‚¡ç¥¨")
        for key, value in filter_log.items():
            if value > 0:
                logger.info(f"  - {key}: {value}åª")

        return df

    def neutralize_factor(self, df: pd.DataFrame, factor_col: str, market_cap_col: str = 'æµé€šå¸‚å€¼(äº¿)', industry_col: str = 'ç”³ä¸‡ä¸€çº§è¡Œä¸š') -> pd.DataFrame:
        """
        å› å­ä¸­æ€§åŒ–ï¼šå‰”é™¤å¸‚å€¼å’Œè¡Œä¸šæš´éœ²

        å…¬å¼ï¼šå› å­æ®‹å·® = åŸå§‹å› å­ - Î²1 * å¸‚å€¼ - Î²2 * è¡Œä¸šå“‘å˜é‡

        Args:
            df: åŒ…å«å› å­ã€å¸‚å€¼ã€è¡Œä¸šçš„DataFrame
            factor_col: å› å­åˆ—å
            market_cap_col: å¸‚å€¼åˆ—å
            industry_col: è¡Œä¸šåˆ—å

        Returns:
            ä¸­æ€§åŒ–åçš„DataFrameï¼Œæ·»åŠ  factor_col_neutral åˆ—
        """
        if factor_col not in df.columns:
            logger.warning(f"å› å­åˆ— {factor_col} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸­æ€§åŒ–")
            return df

        if market_cap_col not in df.columns:
            logger.warning(f"å¸‚å€¼åˆ— {market_cap_col} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸­æ€§åŒ–")
            return df

        if industry_col not in df.columns:
            logger.warning(f"è¡Œä¸šåˆ— {industry_col} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸­æ€§åŒ–")
            return df

        # å‡†å¤‡æ•°æ®
        df_neutral = df[[factor_col, market_cap_col, industry_col, 'ts_code']].copy()
        df_neutral = df_neutral.dropna(subset=[factor_col])

        if len(df_neutral) < 10:
            logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df_neutral)}æ¡)ï¼Œè·³è¿‡ {factor_col} ä¸­æ€§åŒ–")
            return df

        # å…³é”®ï¼šè½¬æ¢æ•°æ®ç±»å‹ä¸ºfloatï¼Œé¿å…Decimalç±»å‹é”™è¯¯
        try:
            df_neutral[factor_col] = pd.to_numeric(df_neutral[factor_col], errors='coerce')
            df_neutral[market_cap_col] = pd.to_numeric(df_neutral[market_cap_col], errors='coerce')
        except Exception as e:
            logger.warning(f"  æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥: {e}")
            return df

        # å†æ¬¡åˆ é™¤NaN
        df_neutral = df_neutral.dropna(subset=[factor_col, market_cap_col])

        if len(df_neutral) < 10:
            logger.warning(f"ç±»å‹è½¬æ¢åæ•°æ®é‡ä¸è¶³({len(df_neutral)}æ¡)ï¼Œè·³è¿‡ {factor_col} ä¸­æ€§åŒ–")
            return df

        # 1. å¯¹æ•°å¸‚å€¼ï¼ˆæ›´ç¬¦åˆçº¿æ€§å‡è®¾ï¼‰
        df_neutral['log_mcap'] = np.log(df_neutral[market_cap_col] + 1e-8)

        # 2. è¡Œä¸šå“‘å˜é‡
        industry_dummies = pd.get_dummies(df_neutral[industry_col], prefix='industry')

        # 3. æ„å»ºç‰¹å¾çŸ©é˜µ
        X = pd.concat([
            df_neutral[['log_mcap']],  # å¸‚å€¼
            industry_dummies           # è¡Œä¸šå“‘å˜é‡
        ], axis=1)

        # 4. ç›®æ ‡å˜é‡
        y = df_neutral[factor_col].values  # è½¬ä¸ºnumpyæ•°ç»„

        # 5. çº¿æ€§å›å½’
        try:
            reg = LinearRegression(fit_intercept=True)
            reg.fit(X, y)

            # 6. é¢„æµ‹å€¼
            y_pred = reg.predict(X)

            # 7. è®¡ç®—æ®‹å·®ï¼ˆä¸­æ€§åŒ–åçš„å› å­ï¼‰
            residual = y - y_pred

            # 8. æ ‡å‡†åŒ–æ®‹å·®ï¼ˆZ-Scoreï¼‰
            residual_mean = residual.mean()
            residual_std = residual.std()

            if residual_std > 0:
                residual_zscore = (residual - residual_mean) / residual_std
            else:
                residual_zscore = residual * 0  # æ ‡å‡†å·®ä¸º0ï¼Œå…¨éƒ¨è®¾ä¸º0

            # 9. åˆå¹¶å›åŸæ•°æ®
            df_neutral[factor_col + '_neutral'] = residual_zscore

            # 10. åˆå¹¶åˆ°åŸDataFrame
            df = df.merge(
                df_neutral[['ts_code', factor_col + '_neutral']],
                on='ts_code',
                how='left'
            )

            # ç»Ÿè®¡ä¿¡æ¯
            logger.info(f"  {factor_col} ä¸­æ€§åŒ–å®Œæˆ:")
            logger.info(f"    å›å½’RÂ²: {reg.score(X, y):.4f}")
            logger.info(f"    æ®‹å·®å‡å€¼: {residual_mean:.6f}")
            logger.info(f"    æ®‹å·®æ ‡å‡†å·®: {residual_std:.6f}")
            if factor_col + '_neutral' in df.columns:
                logger.info(f"    ä¸­æ€§åŒ–åå‡å€¼: {df[factor_col + '_neutral'].mean():.6f}")
                logger.info(f"    ä¸­æ€§åŒ–åæ ‡å‡†å·®: {df[factor_col + '_neutral'].std():.6f}")

        except Exception as e:
            logger.warning(f"  {factor_col} ä¸­æ€§åŒ–å¤±è´¥: {e}")
            df[factor_col + '_neutral'] = np.nan

        return df

    def standardize_factor(self, series: pd.Series) -> pd.Series:
        """
        å› å­æ ‡å‡†åŒ–ï¼šZ-Scoreæ ‡å‡†åŒ–ï¼ˆå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼‰

        Args:
            series: åŸå§‹å› å­åºåˆ—

        Returns:
            æ ‡å‡†åŒ–åçš„åºåˆ—
        """
        if series.isna().all():
            return series

        valid = series.dropna()
        if len(valid) == 0:
            return series

        mean = valid.mean()
        std = valid.std()

        if std == 0 or pd.isna(std):
            logger.warning("æ ‡å‡†å·®ä¸º0æˆ–NaNï¼Œæ— æ³•æ ‡å‡†åŒ–")
            return series * 0

        return (series - mean) / std

    def normalize_factor(self, series: pd.Series, direction: str) -> pd.Series:
        """æ ‡å‡†åŒ–å› å­å€¼åˆ°[0,1]åŒºé—´"""
        if series.isna().all():
            return series

        valid = series.dropna()
        if len(valid) == 0:
            return series

        min_val = valid.min()
        max_val = valid.max()

        if max_val == min_val:
            return pd.Series([0.5] * len(series), index=series.index)

        if direction == 'positive':
            # è¶Šå¤§è¶Šå¥½
            return (series - min_val) / (max_val - min_val)
        else:
            # è¶Šå°è¶Šå¥½
            return 1 - (series - min_val) / (max_val - min_val)

    def calculate_comprehensive_score(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†"""
        logger.info("æ­¥éª¤5: è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†...")

        weights = self.params['weights']
        directions = self.params['directions']

        # æ£€æŸ¥å“ªäº›å› å­å¯ç”¨
        available_factors = []
        factor_columns = {
            'alpha_peg': 'alpha_peg_zscore',
            'alpha_010': 'alpha_010',
            'alpha_038': 'alpha_038',
            'alpha_120cq': 'alpha_120cq',
            'cr_qfq': 'cr_qfq',
            'alpha_pluse': 'alpha_pluse'
        }

        for factor_name, col_name in factor_columns.items():
            if col_name in df.columns and not df[col_name].dropna().empty:
                available_factors.append(factor_name)

        logger.info(f"å¯ç”¨å› å­: {available_factors}")

        # é‡æ–°è®¡ç®—æƒé‡ï¼ˆæŒ‰æ¯”ä¾‹åˆ†é…ï¼‰
        total_weight = sum(weights[f] for f in available_factors)
        if total_weight > 0:
            # å½’ä¸€åŒ–æƒé‡
            normalized_weights = {f: weights[f] / total_weight for f in available_factors}
            logger.info(f"é‡æ–°åˆ†é…æƒé‡: {normalized_weights}")
        else:
            normalized_weights = weights
            logger.warning("æ‰€æœ‰å› å­æƒé‡ä¸º0ï¼Œä½¿ç”¨åŸå§‹æƒé‡")

        # æ ‡å‡†åŒ–å„å› å­
        df['å› å­_ä¼°å€¼'] = self.normalize_factor(df.get('alpha_peg_zscore', pd.Series(np.nan, index=df.index)),
                                               directions['alpha_peg'])
        df['å› å­_è¶‹åŠ¿'] = self.normalize_factor(df.get('alpha_010', pd.Series(np.nan, index=df.index)),
                                               directions['alpha_010'])
        df['å› å­_å¼ºåº¦'] = self.normalize_factor(df.get('alpha_038', pd.Series(np.nan, index=df.index)),
                                               directions['alpha_038'])
        df['å› å­_ä½ç½®'] = self.normalize_factor(df.get('alpha_120cq', pd.Series(np.nan, index=df.index)),
                                               directions['alpha_120cq'])
        df['å› å­_åŠ¨é‡'] = self.normalize_factor(df.get('cr_qfq', pd.Series(np.nan, index=df.index)),
                                               directions['cr_qfq'])
        df['å› å­_é‡èƒ½'] = self.normalize_factor(df.get('alpha_pluse', pd.Series(np.nan, index=df.index)),
                                               directions['alpha_pluse'])

        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆåªä½¿ç”¨å¯ç”¨å› å­ï¼‰
        df['ç»¼åˆå¾—åˆ†'] = 0.0

        if 'alpha_peg' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_ä¼°å€¼'] * normalized_weights['alpha_peg']
        if 'alpha_010' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_è¶‹åŠ¿'] * normalized_weights['alpha_010']
        if 'alpha_038' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_å¼ºåº¦'] * normalized_weights['alpha_038']
        if 'alpha_120cq' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_ä½ç½®'] * normalized_weights['alpha_120cq']
        if 'cr_qfq' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_åŠ¨é‡'] * normalized_weights['cr_qfq']
        if 'alpha_pluse' in available_factors:
            df['ç»¼åˆå¾—åˆ†'] += df['å› å­_é‡èƒ½'] * normalized_weights['alpha_pluse']

        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        df = df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False).reset_index(drop=True)

        if len(df) > 0:
            logger.info(f"ç»¼åˆå¾—åˆ†èŒƒå›´: {df['ç»¼åˆå¾—åˆ†'].min():.4f} ~ {df['ç»¼åˆå¾—åˆ†'].max():.4f}")
        else:
            logger.warning("æ— æœ‰æ•ˆæ•°æ®è®¡ç®—ç»¼åˆå¾—åˆ†")

        return df

    def export_to_excel(self, df: pd.DataFrame):
        """å¯¼å‡ºåˆ°Excel"""
        logger.info("æ­¥éª¤6: å¯¼å‡ºExcel...")

        # æ ‡å‡†åŒ–åˆ—åï¼ˆå°†æ•°æ®åº“åˆ—åè½¬æ¢ä¸ºä¸­æ–‡åˆ—åï¼‰
        column_mapping = {
            'ts_code': 'è‚¡ç¥¨ä»£ç ',
            'circ_mv': 'æµé€šå¸‚å€¼(äº¿)',
            'amount': 'æˆäº¤é¢(ä¸‡)',
        }

        # é‡å‘½ååˆ—
        df_export = df.copy()
        for db_col, cn_col in column_mapping.items():
            if db_col in df_export.columns and cn_col not in df_export.columns:
                df_export.rename(columns={db_col: cn_col}, inplace=True)

        # é€‰æ‹©å¹¶æ’åºåˆ—ï¼ˆåŒ…å«åŸå§‹å› å­å’Œä¸­æ€§åŒ–åå› å­ï¼‰
        output_columns = [
            'è‚¡ç¥¨ä»£ç ', 'ç”³ä¸‡ä¸€çº§è¡Œä¸š', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢(ä¸‡)',
            # åŸå§‹å› å­
            'alpha_peg_zscore', 'alpha_010', 'alpha_038', 'alpha_120cq', 'cr_qfq', 'alpha_pluse',
            # ä¸­æ€§åŒ–åå› å­
            'alpha_peg_neutral', 'alpha_010_neutral', 'alpha_038_neutral', 'alpha_120cq_neutral', 'cr_qfq_neutral', 'alpha_pluse_neutral',
            # ç»¼åˆå¾—åˆ†å’Œæ ‡å‡†åŒ–å› å­
            'ç»¼åˆå¾—åˆ†',
            'å› å­_ä¼°å€¼', 'å› å­_è¶‹åŠ¿', 'å› å­_å¼ºåº¦', 'å› å­_ä½ç½®', 'å› å­_åŠ¨é‡', 'å› å­_é‡èƒ½'
        ]

        # åªä¿ç•™å­˜åœ¨çš„åˆ—
        existing_cols = [col for col in output_columns if col in df_export.columns]
        df_output = df_export[existing_cols].copy()

        # å¯¼å‡ºå®Œæ•´ç»“æœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = '/home/zcy/alpha006_20251223/results/output'
        os.makedirs(output_dir, exist_ok=True)

        # å®Œæ•´ç»“æœ
        full_path = f"{output_dir}/six_factor_scores_{self.target_date}_{timestamp}.xlsx"
        df_output.to_excel(full_path, index=False)
        logger.info(f"å®Œæ•´ç»“æœå·²ä¿å­˜: {full_path}")

        # å‰100å
        top_n = self.params['top_n']
        top_path = f"{output_dir}/six_factor_top{top_n}_{self.target_date}_{timestamp}.xlsx"
        df_output.head(top_n).to_excel(top_path, index=False)
        logger.info(f"å‰{top_n}åå·²ä¿å­˜: {top_path}")

        # ä¿å­˜ç­›é€‰æ—¥å¿—
        log_path = f"{output_dir}/six_factor_log_{self.target_date}_{timestamp}.txt"
        self._save_filter_log(log_path)
        logger.info(f"ç­›é€‰æ—¥å¿—å·²ä¿å­˜: {log_path}")

        return full_path, top_path, log_path

    def _save_filter_log(self, log_path: str):
        """ä¿å­˜ç­›é€‰æ—¥å¿—"""
        with open(log_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("å…­å¤§å› å­é€‰è‚¡ç­–ç•¥ - ç­›é€‰æ—¥å¿—\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"æ‰§è¡Œæ—¥æœŸ: {self.target_date}\n")
            f.write(f"ç­–ç•¥ç‰ˆæœ¬: {self.version}\n")
            f.write(f"ç­–ç•¥åç§°: {self.params['name']}\n")
            f.write(f"è®¡ç®—æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("=" * 80 + "\n")
            f.write("ç­–ç•¥é…ç½®:\n")
            f.write("=" * 80 + "\n\n")

            f.write("åŸºç¡€è¿‡æ»¤:\n")
            for key, value in self.params['filters'].items():
                f.write(f"  - {key}: {value}\n")

            f.write("\nå› å­ç­›é€‰é˜ˆå€¼:\n")
            for key, value in self.params['factor_thresholds'].items():
                f.write(f"  - {key}: {value}\n")

            f.write("\næƒé‡åˆ†é…:\n")
            for key, value in self.params['weights'].items():
                f.write(f"  - {key}: {value}\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("ç­›é€‰è¿‡ç¨‹è®°å½•:\n")
            f.write("=" * 80 + "\n\n")

            for key, value in self.filter_stats.items():
                f.write(f"{key}: {value}\n")

            f.write("\n" + "=" * 80 + "\n")
            f.write("æœ€ç»ˆç»“æœ:\n")
            f.write("=" * 80 + "\n")

    def print_summary(self, df: pd.DataFrame):
        """æ‰“å°æ‰§è¡Œæ€»ç»“"""
        print("\n" + "=" * 80)
        print("æ‰§è¡Œæ€»ç»“")
        print("=" * 80)

        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  ç›®æ ‡æ—¥æœŸ: {self.target_date}")
        print(f"  ç­–ç•¥ç‰ˆæœ¬: {self.version}")
        print(f"  æœ€ç»ˆé€‰è‚¡: {len(df)}åª")

        if len(df) > 0 and 'ç»¼åˆå¾—åˆ†' in df.columns:
            print(f"\nğŸ“ˆ ç»¼åˆå¾—åˆ†ç»Ÿè®¡:")
            print(f"  å‡å€¼: {df['ç»¼åˆå¾—åˆ†'].mean():.4f}")
            print(f"  æ ‡å‡†å·®: {df['ç»¼åˆå¾—åˆ†'].std():.4f}")
            print(f"  æœ€å°å€¼: {df['ç»¼åˆå¾—åˆ†'].min():.4f}")
            print(f"  æœ€å¤§å€¼: {df['ç»¼åˆå¾—åˆ†'].max():.4f}")
            print(f"  ä¸­ä½æ•°: {df['ç»¼åˆå¾—åˆ†'].median():.4f}")

            # å‰10å
            if len(df) >= 10:
                print(f"\nğŸ“ å‰10åä¼˜è´¨ä¸ªè‚¡:")
                for i in range(min(10, len(df))):
                    row = df.iloc[i]
                    stock = row.get('è‚¡ç¥¨ä»£ç ', 'N/A')
                    industry = row.get('ç”³ä¸‡ä¸€çº§è¡Œä¸š', 'N/A')
                    score = row.get('ç»¼åˆå¾—åˆ†', 0)
                    print(f"  {i+1:2d}. {stock:<12} {industry:<8} å¾—åˆ†={score:.4f}")

            # è¡Œä¸šåˆ†å¸ƒ
            if 'ç”³ä¸‡ä¸€çº§è¡Œä¸š' in df.columns:
                industry_counts = df['ç”³ä¸‡ä¸€çº§è¡Œä¸š'].value_counts().head(10)
                if len(industry_counts) > 0:
                    print(f"\nğŸ“Š è¡Œä¸šåˆ†å¸ƒ(å‰10):")
                    for industry, count in industry_counts.items():
                        print(f"  {industry:<8}: {count}åª")

        print("\n" + "=" * 80)
        print("âœ… ä»»åŠ¡å®Œæˆï¼")
        print("=" * 80)

    def run(self):
        """æ‰§è¡Œå®Œæ•´ç­–ç•¥æµç¨‹"""
        try:
            # 1. è·å–å¸‚å€¼å’Œæˆäº¤é¢
            df = self.get_market_data()

            # 2. åŸºç¡€è¿‡æ»¤
            df, _ = self.apply_base_filters(df)

            if len(df) == 0:
                logger.error("åŸºç¡€è¿‡æ»¤åæ— æœ‰æ•ˆè‚¡ç¥¨")
                return

            # 3. è®¡ç®—å› å­
            df = self.calculate_all_factors(df)

            # 4. å› å­ä¸­æ€§åŒ–ï¼ˆå‰”é™¤å¸‚å€¼å’Œè¡Œä¸šæš´éœ²ï¼‰
            logger.info("æ­¥éª¤4: å› å­ä¸­æ€§åŒ–...")
            df = self._neutralize_all_factors(df)

            # 5. å› å­ç­›é€‰ï¼ˆä½¿ç”¨ä¸­æ€§åŒ–åçš„å› å­ï¼‰
            df = self.apply_factor_filters(df)

            if len(df) == 0:
                logger.error("å› å­ç­›é€‰åæ— æœ‰æ•ˆè‚¡ç¥¨")
                return

            # 6. è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆä½¿ç”¨ä¸­æ€§åŒ–åçš„å› å­ï¼‰
            df = self.calculate_comprehensive_score(df)

            # 7. å¯¼å‡ºç»“æœ
            full_path, top_path, log_path = self.export_to_excel(df)

            # 8. æ‰“å°æ€»ç»“
            self.print_summary(df)

            return df

        except Exception as e:
            logger.error(f"ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _neutralize_all_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¯¹æ‰€æœ‰å› å­è¿›è¡Œä¸­æ€§åŒ–å¤„ç†

        å¤„ç†æµç¨‹ï¼š
        1. å¯¹æ¯ä¸ªå› å­è¿›è¡Œå¸‚å€¼+è¡Œä¸šä¸­æ€§åŒ–ï¼ˆalpha_pluseé™¤å¤–ï¼‰
        2. å°†ä¸­æ€§åŒ–åçš„å› å­æ›¿æ¢åŸå› å­ï¼ˆæˆ–æ·»åŠ æ–°åˆ—ï¼‰
        3. æ ‡å‡†åŒ–ä¸ºZ-Score
        4. alpha_pluseä¿æŒåŸå§‹å€¼ï¼ˆäºŒå€¼å› å­ä¸é€‚åˆä¸­æ€§åŒ–ï¼‰
        """
        logger.info("  å¼€å§‹å› å­ä¸­æ€§åŒ–å¤„ç†...")

        # å› å­æ˜ å°„ï¼šåŸå§‹åˆ—å -> ä¸­æ€§åŒ–ååˆ—å
        # æ³¨æ„ï¼šalpha_pluse ä¸è¿›è¡Œä¸­æ€§åŒ–ï¼Œå› ä¸ºå®ƒæ˜¯äºŒå€¼å› å­(0/1)
        factor_map = {
            'alpha_peg_zscore': 'alpha_peg_neutral',
            'alpha_010': 'alpha_010_neutral',
            'alpha_038': 'alpha_038_neutral',
            'alpha_120cq': 'alpha_120cq_neutral',
            'cr_qfq': 'cr_qfq_neutral'
        }

        # ç¡®ä¿æœ‰è¡Œä¸šå’Œå¸‚å€¼æ•°æ®
        if 'ç”³ä¸‡ä¸€çº§è¡Œä¸š' not in df.columns:
            logger.warning("  ç¼ºå°‘è¡Œä¸šæ•°æ®ï¼Œæ— æ³•è¿›è¡Œè¡Œä¸šä¸­æ€§åŒ–")
            return df

        if 'æµé€šå¸‚å€¼(äº¿)' not in df.columns:
            logger.warning("  ç¼ºå°‘å¸‚å€¼æ•°æ®ï¼Œæ— æ³•è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–")
            return df

        # é¢„å¤„ç†ï¼šç¡®ä¿æ‰€æœ‰å› å­åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        for original_col in factor_map.keys():
            if original_col in df.columns:
                try:
                    df[original_col] = pd.to_numeric(df[original_col], errors='coerce')
                except:
                    logger.warning(f"  æ— æ³•è½¬æ¢ {original_col} ä¸ºæ•°å€¼ç±»å‹")
                    df[original_col] = np.nan

        # å¯¹æ¯ä¸ªå› å­è¿›è¡Œä¸­æ€§åŒ–ï¼ˆè·³è¿‡alpha_pluseï¼‰
        for original_col, neutral_col in factor_map.items():
            if original_col in df.columns and not df[original_col].isna().all():
                logger.info(f"  ä¸­æ€§åŒ–å› å­: {original_col}")
                df = self.neutralize_factor(df, original_col, 'æµé€šå¸‚å€¼(äº¿)', 'ç”³ä¸‡ä¸€çº§è¡Œä¸š')

                # å¦‚æœä¸­æ€§åŒ–æˆåŠŸï¼Œä½¿ç”¨ä¸­æ€§åŒ–åçš„å› å­
                if neutral_col in df.columns and not df[neutral_col].isna().all():
                    # æ ‡å‡†åŒ–ä¸ºZ-Scoreï¼ˆä¸­æ€§åŒ–æ—¶å·²æ ‡å‡†åŒ–ï¼Œè¿™é‡Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
                    df[neutral_col] = self.standardize_factor(df[neutral_col])

                    # ç”¨ä¸­æ€§åŒ–å› å­æ›¿æ¢åŸå› å­ï¼ˆç”¨äºåç»­ç­›é€‰å’Œæ‰“åˆ†ï¼‰
                    df[original_col] = df[neutral_col]

                    logger.info(f"  {original_col} å·²æ›¿æ¢ä¸ºä¸­æ€§åŒ–ç‰ˆæœ¬")
                else:
                    logger.warning(f"  {original_col} ä¸­æ€§åŒ–å¤±è´¥ï¼Œä¿ç•™åŸå§‹å€¼")
            else:
                logger.warning(f"  {original_col} æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡ä¸­æ€§åŒ–")

        # alpha_pluse ä¸ä¸­æ€§åŒ–ï¼Œä½†æ·»åŠ  neutral åˆ—ï¼ˆä¸åŸå§‹å€¼ç›¸åŒï¼‰ç”¨äºå¯¼å‡º
        if 'alpha_pluse' in df.columns:
            df['alpha_pluse_neutral'] = df['alpha_pluse']
            logger.info("  alpha_pluse ä¿æŒåŸå§‹å€¼ï¼ˆäºŒå€¼å› å­ä¸ä¸­æ€§åŒ–ï¼‰")

        logger.info("  å› å­ä¸­æ€§åŒ–å®Œæˆ")
        return df


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='å…­å¤§å› å­é€‰è‚¡ç­–ç•¥')
    parser.add_argument('--date', type=str, required=True, help='ç›®æ ‡æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--version', type=str, default='standard',
                       choices=['standard', 'conservative', 'aggressive'],
                       help='ç­–ç•¥ç‰ˆæœ¬')
    args = parser.parse_args()

    print("\n" + "=" * 80)
    print("å…­å¤§å› å­é€‰è‚¡ç­–ç•¥")
    print("=" * 80)
    print(f"æ—¥æœŸ: {args.date}")
    print(f"ç‰ˆæœ¬: {args.version}")
    print("=" * 80 + "\n")

    strategy = SixFactorStrategy(args.date, args.version)
    strategy.run()


if __name__ == '__main__':
    main()
